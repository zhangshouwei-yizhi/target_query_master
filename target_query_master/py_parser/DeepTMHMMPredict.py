import json
import re
import os
import shutil
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from pathlib import Path
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
from Bio import SeqIO
import subprocess

class ProteinTopologyPredictor:
    """
    è›‹ç™½è´¨æ‹“æ‰‘ç»“æ„é¢„æµ‹ä¸æ•°æ®ç®¡ç†ç±»
    åŸºäºUniProtè§£æçš„è›‹ç™½åºåˆ—ã€ä½¿ç”¨DeepTMHMMé¢„æµ‹ï¼Œåè½¬æ¢ä¸ºç»“æ„åŒ–çš„jsonæ–‡ä»¶
    """
    
    # è›‹ç™½è´¨ç±»å‹æè¿°å­—å…¸
    PROTEIN_DESCRIPTIONS = {
        "TM": "transmembrane proteins without a signal peptide",
        "SP+TM": "transmembrane proteins with signal peptide", 
        "SP": "signal peptide",
        "GLOB": "globular proteins without a signal peptide",
        "SP+GLOB": "globular proteins with a signal peptide"
    }
    
    def __init__(self, output_dir: str = "./results"):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.parsed_data = None
    
    def safe_load_json(self, file_path: str) -> Optional[Dict]:
        """
        å®‰å…¨åŠ è½½JSONæ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†
        
        Args:
            file_path: JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            JSONæ•°æ®å­—å…¸æˆ–Noneï¼ˆå¦‚æœå‡ºé”™ï¼‰
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return json.load(file)
        except FileNotFoundError:
            print(f"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} æœªæ‰¾åˆ°")
        except json.JSONDecodeError as e:
            print(f"é”™è¯¯ï¼šJSONæ ¼å¼æ— æ•ˆ - {e}")
        except Exception as e:
            print(f"é”™è¯¯ï¼š{e}")
        return None
    
    def create_fasta_from_uniprot(self, uniprot_json_path: str, gene_name: str) -> str:
        """
        ä»UniProt JSONæ–‡ä»¶åˆ›å»ºFASTAåºåˆ—æ–‡ä»¶
        
        Args:
            uniprot_json_path: UniProt JSONæ–‡ä»¶è·¯å¾„
            gene_name: åŸºå› åç§°
            
        Returns:
            ç”Ÿæˆçš„FASTAæ–‡ä»¶è·¯å¾„
        """
        # éªŒè¯è¾“å…¥æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(uniprot_json_path):
            raise FileNotFoundError(f"UniProt JSONæ–‡ä»¶ä¸å­˜åœ¨: {uniprot_json_path}")
        
        # åˆ›å»ºåŸºå› ä¸“å±ç›®å½•
        gene_dir = self.output_dir / gene_name
        gene_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½UniProt JSONæ•°æ®
        uniprot_data = self.safe_load_json(uniprot_json_path)
        if uniprot_data is None:
            raise ValueError(f"æ— æ³•è§£æUniProt JSONæ–‡ä»¶: {uniprot_json_path}")
        
        # éªŒè¯å¿…éœ€çš„åºåˆ—æ•°æ®
        if 'Sequence' not in uniprot_data:
            raise KeyError(f"UniProt JSONæ–‡ä»¶ä¸­ç¼ºå°‘'Sequence'å­—æ®µ")
        
        # ä»æ–‡ä»¶åè§£æUniProt ID
        filename = os.path.basename(uniprot_json_path)
        parts = filename.split('.')
        uniprot_id = parts[1] if len(parts) > 1 else "unknown"
        
        # ç”Ÿæˆè¾“å‡ºFASTAæ–‡ä»¶è·¯å¾„
        output_fasta_path = gene_dir / f"{gene_name}.fasta"
        
        # å‡†å¤‡åºåˆ—æ•°æ®
        sequence_data = {
            'header': f"{gene_name} {uniprot_id}",
            'sequence': uniprot_data['Sequence']
        }
        
        # åˆ›å»ºFASTAæ–‡ä»¶
        self._create_single_fasta(sequence_data, output_fasta_path)
        
        print(f"å·²ç”ŸæˆFASTAæ–‡ä»¶: {output_fasta_path}")
        return str(output_fasta_path)
    
    def _create_single_fasta(self, sequence_data: Dict, output_path: Path) -> None:
        """
        åˆ›å»ºå•åºåˆ—FASTAæ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            sequence_data: åŒ…å«headerå’Œsequenceçš„å­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # å‚æ•°éªŒè¯
        if not isinstance(sequence_data, dict):
            raise ValueError("åºåˆ—æ•°æ®å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
        
        if 'header' not in sequence_data or 'sequence' not in sequence_data:
            raise ValueError("åºåˆ—æ•°æ®å¿…é¡»åŒ…å«'header'å’Œ'sequence'é”®")
        
        if not sequence_data['header'].strip():
            raise ValueError("headerä¸èƒ½ä¸ºç©º")
        
        if not sequence_data['sequence'].strip():
            raise ValueError("sequenceä¸èƒ½ä¸ºç©º")
        
        # åˆ›å»ºåºåˆ—è®°å½•
        try:
            seq_obj = Seq(sequence_data['sequence'])
            header_parts = sequence_data['header'].split(maxsplit=1)
            seq_id = header_parts[0]
            description = header_parts[1] if len(header_parts) > 1 else ""
            
            seq_record = SeqRecord(seq_obj, id=seq_id, description=description)
            
            # å†™å…¥æ–‡ä»¶
            with open(output_path, "w") as output_handle:
                SeqIO.write(seq_record, output_handle, "fasta")
                
        except Exception as e:
            raise ValueError(f"åˆ›å»ºFASTAæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def run_deeptmhmm_prediction(self, fasta_path: str) -> str:
        """
        è¿è¡ŒDeepTMHMMé¢„æµ‹
        
        Args:
            fasta_path: è¾“å…¥FASTAæ–‡ä»¶è·¯å¾„
            
        Returns:
            é¢„æµ‹ç»“æœç›®å½•è·¯å¾„ï¼ˆbiolib_resultsæ‰€åœ¨ç›®å½•ï¼‰
        """
        fasta_path = os.path.abspath(fasta_path)
        if not os.path.exists(fasta_path):
            raise FileNotFoundError(f"FASTAæ–‡ä»¶ä¸å­˜åœ¨: {fasta_path}")
        
        # è·å–FASTAæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆå³åŸºå› ä¸“å±ç›®å½•ï¼‰
        gene_dir = Path(fasta_path).parent
        
        print(f"è¿è¡ŒDeepTMHMMé¢„æµ‹...")
        print(f"è¾“å…¥FASTA: {fasta_path}")
        print(f"å·¥ä½œç›®å½•: {gene_dir}")
        
        try:
            # åœ¨åŸºå› ç›®å½•ä¸‹è¿è¡ŒDeepTMHMM
            result = subprocess.run([
                'biolib', 'run', 'DTU/DeepTMHMM', 
                '--fasta', fasta_path
            ], cwd=gene_dir, capture_output=True, text=True, check=True)
            
            # DeepTMHMMä¼šåœ¨å½“å‰ç›®å½•ç”Ÿæˆbiolib_resultsæ–‡ä»¶å¤¹
            biolib_results_dir = gene_dir / "biolib_results"
            
            if not biolib_results_dir.exists():
                raise FileNotFoundError(f"DeepTMHMMæœªç”Ÿæˆç»“æœç›®å½•: {biolib_results_dir}")
            
            print("DeepTMHMMé¢„æµ‹å®Œæˆ")
            return str(gene_dir)  # è¿”å›åŸºå› ç›®å½•è·¯å¾„ï¼Œå› ä¸ºbiolib_resultsåœ¨å…¶ä¸­
            
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"DeepTMHMMè¿è¡Œå¤±è´¥: {e.stderr}")
        except Exception as e:
            raise RuntimeError(f"è¿è¡ŒDeepTMHMMæ—¶å‡ºé”™: {str(e)}")
    
    def parse_deeptmhmm_results(self, deeptmhmm_output_dir: str, gene_name: str) -> Dict[str, Any]:
        """
        è§£æDeepTMHMMé¢„æµ‹ç»“æœå¹¶è¿”å›ç»“æ„åŒ–æ•°æ®
        
        Args:
            deeptmhmm_output_dir: DeepTMHMMè¾“å‡ºç›®å½•ï¼ˆåŸºå› ç›®å½•ï¼‰
            gene_name: åŸºå› å
            
        Returns:
            ç»“æ„åŒ–çš„é¢„æµ‹æ•°æ®
        """
        deeptmhmm_dir = Path(deeptmhmm_output_dir)
        biolib_results_dir = deeptmhmm_dir / "biolib_results"
        
        # æ£€æŸ¥å¿…è¦çš„è¾“å‡ºæ–‡ä»¶
        gff_file = biolib_results_dir / "TMRs.gff3"
        fasta_file = biolib_results_dir / "predicted_topologies.3line"
        
        if not gff_file.exists():
            raise FileNotFoundError(f"GFFæ–‡ä»¶ä¸å­˜åœ¨: {gff_file}")
        if not fasta_file.exists():
            raise FileNotFoundError(f"æ‹“æ‰‘ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {fasta_file}")
        
        # è§£æç»“æœ
        genes_info = self._parse_gff_content(str(gff_file))
        genes_seq_info = self._parse_fasta_like_content(str(fasta_file))
        
        if not genes_info:
            raise ValueError("æ— æ³•ä»GFFæ–‡ä»¶ä¸­è§£æåˆ°åŸºå› ä¿¡æ¯")
        
        # ç”ŸæˆJSONæ•°æ®
        json_data = self._generate_json_structure(genes_info, genes_seq_info, gene_name)
        self.parsed_data = json_data
        
        return json_data
    
    def _parse_gff_content(self, gff_file: str) -> Dict[str, Dict]:
        """
        è§£æGFFæ–‡ä»¶å†…å®¹ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        """
        genes = {}
        
        try:
            with open(gff_file, 'r', encoding='utf-8') as file:
                gff_text = file.read()
        except Exception as e:
            print(f"è¯»å–GFFæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return {}
        
        lines = gff_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            if not line or line == '//':
                continue
                
            if line.startswith('#'):
                if 'Length:' in line:
                    match = re.search(r'#\s*(\w+)\s*Length:\s*(\d+)', line)
                    if match:
                        gene_name = match.group(1)
                        if gene_name not in genes:
                            genes[gene_name] = {'length': 0, 'num_tmrs': 0, 'regions': []}
                        genes[gene_name]['length'] = int(match.group(2))
                elif 'Number of predicted TMRs:' in line:
                    match = re.search(r'#\s*(\w+)\s*Number of predicted TMRs:\s*(\d+)', line)
                    if match:
                        gene_name = match.group(1)
                        if gene_name not in genes:
                            genes[gene_name] = {'length': 0, 'num_tmrs': 0, 'regions': []}
                        genes[gene_name]['num_tmrs'] = int(match.group(2))
            else:
                parts = line.split()
                if len(parts) >= 4:
                    gene_name = parts[0]
                    region_type = parts[1]
                    start, end = int(parts[2]), int(parts[3])
                    
                    if gene_name not in genes:
                        genes[gene_name] = {'length': 0, 'num_tmrs': 0, 'regions': []}
                    
                    genes[gene_name]['regions'].append({
                        'predicted region': region_type,
                        'start': start,
                        'end': end
                    })
        
        return genes
    
    def _parse_fasta_like_content(self, fasta_file: str) -> Dict[str, Dict]:
        """
        è§£æç±»ä¼¼FASTAæ ¼å¼çš„æ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        """
        try:
            with open(fasta_file, 'r', encoding='utf-8') as file:
                fasta_text = file.read()
        except Exception as e:
            print(f"è¯»å–FASTAæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return {}
        
        clean_text = re.sub(r'<[^>]+>', '', fasta_text)
        lines = [line.strip() for line in clean_text.split('\n') if line.strip()]
        
        genes_seq_info = {}
        i = 0
        
        while i < len(lines):
            line = lines[i]
            
            if line.startswith('>'):
                header_match = re.match(r'>(\w+)\s*\|\s*(\w+)', line)
                if header_match:
                    gene_name = header_match.group(1)
                    protein_type = header_match.group(2)
                    
                    if i + 2 < len(lines):
                        amino_acids = lines[i + 1].strip()
                        topology = lines[i + 2].strip()
                        
                        genes_seq_info[gene_name] = {
                            'predicted protein type': protein_type,
                            'amino acids': amino_acids,
                            'predicted amino acid topology type': topology
                        }
                        
                        i += 3
                        continue
            i += 1
        
        return genes_seq_info
    
    def _generate_json_structure(self, genes_info: Dict, genes_seq_info: Dict, 
                               gene_name: str) -> Dict[str, Any]:
        """
        ç”ŸæˆJSONæ•°æ®ç»“æ„ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        """
        gene_data = genes_info.get(gene_name, {})
        
        return {
            "gene_information": {
                "gene_name": gene_name
            },
            "DeepTMHMM": {
                "Region": gene_data.get('regions', []),
                "Protein Length": gene_data.get('length', np.nan),
                "Number of predicted TMRs": gene_data.get('num_tmrs', np.nan),
                "Sequence": genes_seq_info.get(gene_name, {
                    "predicted protein type": "",
                    "amino acids": "", 
                    "predicted amino acid topology type": ""
                })
            },
            "Protein description": self.PROTEIN_DESCRIPTIONS,
            "data_metadata": {
                "data_source": "DeepTMHMM for Transmembrane Topology Prediction and Classification",
                "processing_date": pd.Timestamp.now().strftime("%Y-%m-%d"),
            }
        }
    
    def save_to_file(self, filename: str, gene_name: Optional[str] = None) -> None:
        """
        å°†è§£æç»“æœä¿å­˜åˆ°æ–‡ä»¶
        
        Args:
            filename (str): è¾“å‡ºæ–‡ä»¶å
            gene_name (str, optional): åŸºå› åï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å·²è§£æçš„æ•°æ®
        """
        if not self.parsed_data:
            if gene_name:
                # å¦‚æœæ²¡æœ‰è§£ææ•°æ®ä½†æœ‰åŸºå› åï¼Œå¯ä»¥å°è¯•è¿è¡Œå®Œæ•´æµç¨‹
                raise ValueError("æ²¡æœ‰è§£ææ•°æ®ï¼Œè¯·å…ˆè¿è¡Œå®Œæ•´æµç¨‹æˆ–æä¾›åŸºå› åå’ŒUniProt JSONæ–‡ä»¶è·¯å¾„")
            else:
                raise ValueError("æ²¡æœ‰è§£ææ•°æ®ä¸”æœªæä¾›åŸºå› å")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(filename)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨json.dumpä¿å­˜æ•°æ®[1](@ref)
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(self.parsed_data, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            raise IOError(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    def run_complete_pipeline(self, uniprot_json_path: str, 
                            cleanup: bool = True) -> str:
        """
        è¿è¡Œå®Œæ•´çš„å¤„ç†æµç¨‹
        
        Args:
            uniprot_json_path: UniProt JSONæ–‡ä»¶è·¯å¾„
            cleanup: æ˜¯å¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            
        Returns:
            æœ€ç»ˆç”Ÿæˆçš„JSONæ–‡ä»¶è·¯å¾„
        """
        print("=" * 50)
        print("å¼€å§‹è›‹ç™½è´¨æ‹“æ‰‘ç»“æ„é¢„æµ‹æµç¨‹")
        print("=" * 50)
        
        try:
            # ä»æ–‡ä»¶åè§£æåŸºå› å
            gene_name = Path(uniprot_json_path).stem.split('.')[0]
            
            # æ­¥éª¤1: ä»UniProt JSONç”ŸæˆFASTAæ–‡ä»¶
            print(f"\n1. ä»UniProt JSONç”ŸæˆFASTAåºåˆ—ï¼ˆåŸºå› : {gene_name}ï¼‰...")
            fasta_path = self.create_fasta_from_uniprot(uniprot_json_path, gene_name)
            
            # æ­¥éª¤2: è¿è¡ŒDeepTMHMMé¢„æµ‹
            print("\n2. è¿è¡ŒDeepTMHMMé¢„æµ‹...")
            deeptmhmm_result_dir = self.run_deeptmhmm_prediction(fasta_path)
            
            # æ­¥éª¤3: è§£æç»“æœç”Ÿæˆç»“æ„åŒ–JSON
            print("\n3. è§£æé¢„æµ‹ç»“æœç”ŸæˆJSONæ•°æ®...")
            json_data = self.parse_deeptmhmm_results(deeptmhmm_result_dir, gene_name)
            
            # æ­¥éª¤4: ä¿å­˜JSONæ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
            json_output_path = self.output_dir / f"{gene_name}.DeepTMHMM_data.json"
            self.save_to_file(str(json_output_path))
            
            # æ­¥éª¤5: æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆåˆ é™¤åŸºå› ä¸“å±ç›®å½•ï¼‰
            if cleanup:
                print("\n4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                gene_dir = self.output_dir / gene_name
                if gene_dir.exists():
                    shutil.rmtree(gene_dir)
                    print(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {gene_dir}")
            
            print("\n" + "=" * 50)
            print("æµç¨‹å®Œæˆ!")
            print(f"æœ€ç»ˆç»“æœ: {json_output_path}")
            print("=" * 50)
            
            return json_data
            
        except Exception as e:
            print(f"\næµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}")
            raise
    
    def batch_process(self, uniprot_json_files: List[str], 
                    cleanup: bool = True) -> List[str]:
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªUniProt JSONæ–‡ä»¶
        
        Args:
            uniprot_json_files: UniProt JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            cleanup: æ˜¯å¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            
        Returns:
            ç”Ÿæˆçš„JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        results = []
        
        for i, json_file in enumerate(uniprot_json_files, 1):
            print(f"\nå¤„ç†æ–‡ä»¶ {i}/{len(uniprot_json_files)}: {json_file}")
            try:
                result_path = self.run_complete_pipeline(json_file, cleanup)
                results.append(result_path)
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {json_file}: {e}")
                continue
        
        return results
